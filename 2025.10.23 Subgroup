### FIGURE 1 ###
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
from scipy.stats import pearsonr

df = pd.read_csv('new_df.csv')
pdp1_df = df[df['target']=='PDP1']
# Filter rows where the 'gene' column contains 'Pdh'
pdh_df = pdp1_df[pdp1_df['gene_phos'].str.contains('Pdha1', na=False)]

# Create scatter plot comparing prot_fc and phospho_fc
plt.figure(figsize=(10, 8))
sns.scatterplot(data=pdp1_df, x='prot_fc', y='phospho_fc', alpha=0.5)

# Highlight points in pdh_df in red
sns.scatterplot(data=pdh_df, x='prot_fc', y='phospho_fc', color='red', label='Highlighted Points')

# Add labels and title
plt.xlabel('Log2 Fold Change (prot_fc)')
plt.ylabel('Log2 Fold Change (phospho_fc)')
plt.title('Scatter Plot of Phospho vs Protein Fold Change')

# Add labels for points in pdh_df (optional)
texts = []
for i, row in pdh_df.iterrows():
    texts.append(plt.text(row['prot_fc'], row['phospho_fc'], row['gene_phos']))

# Add a 45-degree line (x=y)
min_val = min(pdp1_df['prot_fc'].min(), pdp1_df['phospho_fc'].min())
max_val = max(pdp1_df['prot_fc'].max(), pdp1_df['phospho_fc'].max())
plt.plot([min_val, max_val], [min_val, max_val], color='gray', linestyle='--')

plt.legend()
plt.grid(True)
plt.show()
######################################################################
#### FIGURE 2 #####
input_df = pd.read_csv('new_df.csv')
target_name = "PDP1" #### OR HDHD5 when I was doing this for HDHD5 analysis. 
input_df = input_df[input_df['MitoCarta3']=='yes'] ## This line was removed when doing the all phosphosite analysis 

def make_ptmsig_input (df,name):
  df_short = df[['gene_phos', 'phospho_fc', 'phospho_pval']] #### THIS MAY HAVE TO BE CHANGED BASED ON THE INPUT FILE!!
  def extract_id(phospho_string):
    match_multiple = re.search(r'^\w+_(\w+) (\d+)xPhospho \[(.*?)\]', phospho_string) # Added non-greedy match and modified regex
    if match_multiple:
        protein_id = match_multiple.group(1)
        sites = match_multiple.group(3).split(';')
        return [f"{protein_id};{site.strip()}-p" for site in sites]

    match_single = re.search(r'^\w+_(\w+) 1xPhospho \[(.*?)\]', phospho_string) # Added non-greedy match and modified regex
    if match_single:
        return [f"{match_single.group(1)};{match_single.group(2)}-p"]

    return None

# Apply the function and expand the list of IDs into separate rows
  df_short = df_short.copy()
  df_short['id'] = df_short['gene_phos'].apply(extract_id)
  df_short = df_short.explode('id').reset_index(drop=True)
  df_short['sign']=np.sign(df_short['phospho_fc'])
  df_short['Score']=-1*np.log10(df_short['phospho_pval'])*df_short['sign']
  out_data = df_short[['id', 'Score']].dropna().copy()
  display(out_data.head())
  output_path = f"{name}_ptmsigINPUT.gct"
  out_data.to_csv(output_path, sep="\t", index=False)

    # Prepend the header for GCT format
  header1 = "#1.3"
  header2 = f"{out_data.shape[0]}\t{out_data.shape[1] - 1}\t0\t0"
  with open(output_path, 'r+') as f:
          content = f.read()
          f.seek(0, 0)
          f.write(header1 + "\n")
          f.write(header2 + "\n")
          f.write(content)

make_ptmsig_input(input_df, 'targetname_all/mito')
### DOWNLOAD THE GCT FILE AN IMPORT WITH UNIPROT FASTA FILE TO THIS WEBSITE:
### https://cloud.genepattern.org/gp/pages/index.jsf?lsid=urn:lsid:8080.gpserver.ip-172-31-26-71.ip-172-31-26-71.ec2.internal:genepatternmodules:69:4
######## The above code made the specific file that was loaded into the above website. 
#### The barplots are made below:
ptmsig_output = pd.read_csv('PDP1_all_ptmsig_output_cmbd.gct', sep='\t', skiprows=2) #### This was changed to respective PTMsig output combined file. 
ptmsig_output['abs']=abs(ptmsig_output['Score'])
ptmsig_output = ptmsig_output.sort_values(by='abs', ascending=False)
top20 = ptmsig_output.head(20)

top20 = top20.sort_values(by='Score', ascending=True)

# Create the bar chart
plt.figure(figsize=(10, 8))

# Define colors based on pvalue.Score using less bright colors
colors = ['salmon' if pval < 0.05 else 'lightsteelblue' for pval in top20['fdr.pvalue.Score']]


plt.barh(top20['id'], top20['Score'], color=colors)
plt.xlabel('Score')
plt.ylabel('PTM Signature')
plt.title('Top 20 PTM Signatures by Enrichment Score for PDP1')
plt.tight_layout()
plt.show()

###################################
### FIGURE 3 ##### This was used to generate the correlation figure ##### 
heatmap_df = new_df[new_df['target'].isin(['PDP1', 'HDHD5'])]

# Pivot the DataFrame
heatmap_pivot = heatmap_df.pivot_table(index='gene_phos', columns='target', values='phospho_fc')
# Create a scatter plot of PDP1 vs HDHD5 phospho_fc values
plt.figure(figsize=(8, 6))
plt.scatter(heatmap_pivot['PDP1'], heatmap_pivot['HDHD5'], alpha=0.5)

# Add line of best fit
# Remove NaN values before calculating the line of best fit
df_for_fit = heatmap_pivot[['PDP1', 'HDHD5']].dropna()
m, b = np.polyfit(df_for_fit['PDP1'], df_for_fit['HDHD5'], 1)
plt.plot(df_for_fit['PDP1'], m*df_for_fit['PDP1'] + b, color='red')

# Calculate R-squared value
correlation_coefficient, _ = pearsonr(df_for_fit['PDP1'], df_for_fit['HDHD5'])
r_squared = correlation_coefficient**2

plt.title('Scatter Plot of Phospho_fc: PDP1 vs HDHD5')
plt.xlabel('PDP1 phospho_fc')
plt.ylabel('HDHD5 phospho_fc')
plt.grid(True)
plt.text(0.05, 0.95, f'R-squared: {r_squared:.2f}', transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')
plt.tight_layout()
plt.show()

########################################
##### THIS CODE WAS USED TO CREATE FIGURE 5A-C. For the 2 growth assay curves. inos auxo analysis sheet is taken from teh raw data from sean. 
import pandas as pd
df = pd.read_excel('inos auxo analysis.xlsx')
column_mapping = {
    'F1': 'WT_YPD_1', 'F2': 'WT_YPD_2', 'F3': 'WT_YPD_3',
    'F4': 'YKR_YPD_1', 'F5': 'YKR_YPD_2', 'F6': 'YKR_YPD_3',
    'F7': 'WT_YPDG_1', 'F8': 'WT_YPDG_2', 'F9': 'WT_YPDG_3',
    'F10': 'YKR_YPDG_1', 'F11': 'YKR_YPDG_2', 'F12': 'YKR_YPDG_3',
    'G1': 'WT_SCD_1', 'G2': 'WT_SCD_2', 'G3': 'WT_SCD_3',
    'G4': 'YKR_SCD_1', 'G5': 'YKR_SCD_2', 'G6': 'YKR_SCD_3',
    'G7': 'WT_SCDG_1', 'G8': 'WT_SCDG_2', 'G9': 'WT_SCDG_3',
    'G10': 'YKR_SCDG_1', 'G11': 'YKR_SCDG_2', 'G12': 'YKR_SCDG_3',
    'H1': 'WT_SCD-inos+chol_1', 'H2': 'WT_SCD-inos+chol_2', 'H3': 'WT_SCD-inos+chol_3',
    'H4': 'YKR_SCD-inos+chol_1', 'H5': 'YKR_SCD-inos+chol_2', 'H6': 'YKR_SCD-inos+chol_3',
    'H7': 'WT_SCDG-inos+chol_1', 'H8': 'WT_SCDG-inos+chol_2', 'H9': 'WT_SCDG-inos+chol_3',
    'H10': 'YKR_SCDG-inos+chol_1', 'H11': 'YKR_SCDG-inos+chol_2', 'H12': 'YKR_SCDG-inos+chol_3'
}

df.rename(columns=column_mapping, inplace=True)

df_melted = df.melt(id_vars=['Time'], var_name='variable', value_name='value')
df_melted['Sample_Type'] = df_melted['variable'].apply(lambda x: '_'.join(x.split('_')[:-1]))
df_melted['Time'] = pd.to_timedelta(df_melted['Time'].astype(str))
df_grouped = df_melted.groupby(['Time', 'Sample_Type'])['value'].mean().reset_index()

import seaborn as sns
import matplotlib.pyplot as plt

# Separate data into two groups based on 'G' in Sample_Type
df_grouped_G = df_grouped[df_grouped['Sample_Type'].str.contains('G')].copy()
df_grouped_no_G = df_grouped[~df_grouped['Sample_Type'].str.contains('G')].copy()

# Plot for sample types with 'G'
plt.figure(figsize=(12, 8))
ax_G = sns.lineplot(data=df_grouped_G, x='Time', y='value', hue='Sample_Type', legend=False)
plt.title('Average Growth Over Time for Sample Types-Respiration')
plt.xlabel('Time')
plt.ylabel('Average Growth')

# Add labels to the lines for 'G' group
for sample_type in df_grouped_G['Sample_Type'].unique():
    last_data_point = df_grouped_G[df_grouped_G['Sample_Type'] == sample_type].iloc[-1]
    ax_G.text(last_data_point['Time'].total_seconds(), last_data_point['value'], sample_type, fontsize=9, verticalalignment='bottom')

plt.show()

# Plot for sample types without 'G'
plt.figure(figsize=(12, 8))
ax_no_G = sns.lineplot(data=df_grouped_no_G, x='Time', y='value', hue='Sample_Type', legend=False)
plt.title('Average Growth Over Time for Sample Types-Fermentation')
plt.xlabel('Time')
plt.ylabel('Average Growth')

# Add labels to the lines for no 'G' group
for sample_type in df_grouped_no_G['Sample_Type'].unique():
    last_data_point = df_grouped_no_G[df_grouped_no_G['Sample_Type'] == sample_type].iloc[-1]
    ax_no_G.text(last_data_point['Time'].total_seconds(), last_data_point['value'], sample_type, fontsize=9, verticalalignment='bottom')

plt.show()
################################################################################################
#### FIGURE 6 Yeast LIPIDOMICS comparing my lipidomics to Y3K ############
import pandas as pd
## Prior to importing this file, I manually identified CoQ8 and changed the KeepID to True. 
df = pd.read_csv('YKR_DegreaserResults.csv') ## This is the output file for my yeast lipidomcis 
# Rename columns
df = df.rename(columns={
    '20251016_W303_1.raw (F1)': 'WT_1',
    '20251016_W303_2.raw (F2)': 'WT_2',
    '20251016_W303_3.raw (F3)': 'WT_3',
    '20251016_YKR070W_1.raw (F4)': 'YKR_1',
    '20251016_YKR070W_2.raw (F5)': 'YKR_2',
    '20251016_YKR070W_3.raw (F6)': 'YKR_3',
    'Blank_20251017070019.raw (F7)': 'Blank_1',
    'Blank_20251017094956.raw (F8)': 'Blank_2',
    'Blank_20251017115707.raw (F9)': 'Blank_3'
})
df = df[df['KeepID'] == True]
df['Is_Duplicate'] = df.duplicated(subset=['Annotation'], keep=False)

## Drop innacurate duplicates. 
df_no_duplicates = df.sort_values(by=['Annotation', 'RTpredictionDifference']).drop_duplicates(subset=['Annotation'], keep='first')
dropped_rows = df[~df.index.isin(df_no_duplicates.index)]
duplicates = df[df['Is_Duplicate'] == True]
duplicates_sorted = duplicates.sort_values(by=['Annotation', 'RTpredictionDifference'])
df = df_no_duplicates

## Scale according to CoQ8 values
coq8_row = df[df['Annotation']=='CoQ8']
wt_cols = ['WT_1', 'WT_2', 'WT_3']
ykr_cols = ['YKR_1', 'YKR_2', 'YKR_3']

coq8_avg = coq8_row[wt_cols + ykr_cols].mean(axis=1).iloc[0]
print(coq8_avg)
wt_sf = coq8_avg /coq8_row[wt_cols]
ykr_sf = coq8_avg / coq8_row[ykr_cols]

# Create a new DataFrame for scaled data, copying the original
df_scaled = df.copy()

# Apply scaling factors to WT columns
for col in wt_cols:
    df_scaled[col] = df_scaled[col] * wt_sf[col].iloc[0]

# Apply scaling factors to YKR columns
for col in ykr_cols:
    df_scaled[col] = df_scaled[col] * ykr_sf[col].iloc[0]display(ykr_sf)

#### Log 2 transform values 
import numpy as np

# Create a new DataFrame for log2-transformed data, copying the blank-removed DataFrame
df_log2_transformed = df_scaled.copy()

# Identify WT and YKR columns from the blank-removed DataFrame
wt_cols_blank_removed = [col for col in df_scaled.columns if 'WT_' in col]
ykr_cols_blank_removed = [col for col in df_scaled.columns if 'YKR_' in col]

# Apply log2 transformation to WT and YKR columns, handling non-positive values
for col in wt_cols_blank_removed + ykr_cols_blank_removed:
    # Replace non-positive values with NaN before log2 transformation
    df_log2_transformed[col] = df_log2_transformed[col].replace(0, np.nan) # Replace 0 with NaN
    df_log2_transformed[col] = df_log2_transformed[col].apply(lambda x: np.nan if x < 0 else x) # Replace negative with NaN
    df_log2_transformed[col] = np.log2(df_log2_transformed[col])

##### Calcuate log2 fc 
# Calculate the average of WT columns and create a new column 'WT_average'
wt_cols_log2 = [col for col in df_log2_transformed.columns if 'WT_' in col and col != 'WT_average']
df_log2_transformed['WT_average'] = df_log2_transformed[wt_cols_log2].mean(axis=1)

# Calculate the average of YKR columns and create a new column 'YKR_average'
ykr_cols_log2 = [col for col in df_log2_transformed.columns if 'YKR_' in col and col != 'YKR_average']
df_log2_transformed['YKR_average'] = df_log2_transformed[ykr_cols_log2].mean(axis=1)

# Calculate the Log2 fold change and create a new column 'Log2fc'
df_log2_transformed['Log2fc'] = df_log2_transformed['YKR_average'] - df_log2_transformed['WT_average']

# Display the first few rows of the DataFrame with the new columns
display(df_log2_transformed.head())

########Create p value and adj p val
from scipy.stats import ttest_ind
from statsmodels.sandbox.stats.multicomp import multipletests
import numpy as np

# Create new columns for p-value and adjusted p-value
df_log2_transformed['pval'] = np.nan
df_log2_transformed['adj_pval'] = np.nan

# Identify WT and YKR columns
wt_cols_log2 = [col for col in df_log2_transformed.columns if 'WT_' in col and col != 'WT_average']
ykr_cols_log2 = [col for col in df_log2_transformed.columns if 'YKR_' in col and col != 'YKR_average']

# Convert relevant columns to numeric, coercing errors to NaN
for col in wt_cols_log2 + ykr_cols_log2:
    df_log2_transformed[col] = pd.to_numeric(df_log2_transformed[col], errors='coerce')


# Perform t-test for each row and store the p-value
for index, row in df_log2_transformed.iterrows():
    # Drop NaN values and convert to numpy array before performing t-test
    wt_data = row[wt_cols_log2].dropna().to_numpy(dtype=float)
    ykr_data = row[ykr_cols_log2].dropna().to_numpy(dtype=float)

    # Ensure there are enough data points to perform t-test
    if len(wt_data) >= 2 and len(ykr_data) >= 2:
        t_stat, p_val = ttest_ind(wt_data, ykr_data, equal_var=False) # Using Welch's t-test
        df_log2_transformed.loc[index, 'pval'] = p_val
    else:
        df_log2_transformed.loc[index, 'pval'] = np.nan # Set p-value to NaN if not enough data

# Apply Benjamini-Hochberg correction for multiple testing
# Filter out rows with NaN p-values before correction
valid_pvals = df_log2_transformed['pval'].dropna()
if not valid_pvals.empty:
    reject, pvals_corrected, _, _ = multipletests(valid_pvals, method='fdr_bh') # FDR - BH correction

    # Map the corrected p-values back to the original DataFrame
    df_log2_transformed.loc[valid_pvals.index, 'adj_pval'] = pvals_corrected

#### Create W303 Volcano plot. 
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Create volcano plot
plt.figure(figsize=(10, 8))
sns.scatterplot(data=df_log2_transformed, x='Log2fc', y=-np.log10(df_log2_transformed['pval']), alpha=0.5)

# Add labels and title
plt.xlabel('Log2 Fold Change')
plt.ylabel('-log10(p-value)')
plt.title('YKR070W W303')

# Label points with Log2 fold change > 1
highlight_df = df_log2_transformed[abs(df_log2_transformed['Log2fc']) > .4]
texts = []
for i, row in highlight_df.iterrows():
    texts.append(plt.text(row['Log2fc'], -np.log10(row['pval']), row['Annotation']))

plt.grid(True)
plt.show()
########## This is Figure 6B, which is imported from Y3K, YKR070W Lipidomics data. 
y3k_df = pd.read_csv('Y3K_Perturbations_YKR070W_Respiration-RDR.csv')
y3k_df = y3k_df[y3k_df['Molecule Type']=='LIPID']
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Create volcano plot
plt.figure(figsize=(10, 8))
sns.scatterplot(data=y3k_df, x='∆LFQ', y=-np.log10(y3k_df['P-Value']), alpha=0.5)

# Add labels and title
plt.xlabel('∆LFQ')
plt.ylabel('-log10(p-value)')
plt.title('Y3K-YKR070W BY4742')

# Label points with Log2 fold change > 1
highlight_df = y3k_df[abs(y3k_df['∆LFQ']) > .4]
texts = []
for i, row in highlight_df.iterrows():
    texts.append(plt.text(row['∆LFQ'], -np.log10(row['P-Value']), row['Molecule Name']))

plt.grid(True)
plt.show()


##### This compares the fc of lipid classes between Y3K and my lipidomics data. 
import re
import matplotlib.pyplot as plt
import seaborn as sns

y3k_df['LipidClass'] = y3k_df['Molecule Name'].apply(lambda x: re.sub(r'\(.*\)', '', x).strip())


# Select relevant columns from df_log2_transformed and rename 'Log2fc' to 'Value'
df1_subset = df_log2_transformed[['LipidClass', 'Log2fc']].copy()
df1_subset = df1_subset.rename(columns={'Log2fc': 'Value'})
df1_subset['Dataset'] = 'W303'

# Select relevant columns from y3k_df and rename '∆LFQ' to 'Value'
df2_subset = y3k_df[['LipidClass', '∆LFQ']].copy()
df2_subset = df2_subset.rename(columns={'∆LFQ': 'Value'})
df2_subset['Dataset'] = 'BY4742'

# Rename LPC to LysoPC in df2_subset
df2_subset['LipidClass'] = df2_subset['LipidClass'].replace('LPC', 'LysoPC')

# Combine the two subsets
combined_df = pd.concat([df1_subset, df2_subset])

# Create the combined boxplot
plt.figure(figsize=(12, 8))
sns.boxplot(data=combined_df, x='Value', y='LipidClass', hue='Dataset')
sns.stripplot(data=combined_df, x='Value', y='LipidClass', hue='Dataset', size=4, jitter=True, dodge=True, linewidth=1, edgecolor='black')
plt.xlabel('Fold Change (Log2fc for W303, ∆LFQ for BY4742)')
plt.ylabel('Lipid Class')
plt.title('Fold Change by Lipid Class - YKR070W v.s. WT (W303-This Experiment / BY4742-Y3K)')
plt.grid(True)
plt.show()
